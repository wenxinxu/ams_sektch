import numpy as np 
from collections import Counter 

#### utility funcs. 

def get_s1_s2(n, k, lambd, epsilon, sketch_type):
    if sketch_type == 'Fk':
        s1 = int(np.ceil(  8*k*n**(1-1/k)/lambd**2  ))
        s2 = 2 * np.log(1/epsilon)
        return s1,s2 

    elif sketch_type == 'ams':
        s1 = int(np.ceil(16 / lambd**2 ))
        s2 = int(np.ceil(2 * np.log(1 /epsilon)))
        return s1, s2 

    else: 
        raise NotImplementedError()


def get_frequency_vector(stream):
    counter = Counter(stream)
    frequency_vector = np.array([counter[i] for i in sorted(list(counter))])
    return frequency_vector

#m is hte size of the stream. 
def stream_distribution(mode,m, param1=0,param2=0):
    mode = mode.lower()

    #low is always 0 
    #param1 is highest value in uniform. 
    if mode=="uniform":
        return np.random.randint(low=0, high=param1, size=m)

    #param1 is zipf coefficient. 
    if mode=="zipf":
        return np.random.zipf(param1, m)

    #param1 is mean 
    #param2 is std. 
    if mode=="gaussian":
        return (np.floor(np.random.normal(loc=param1, scale=param2, size=m))).astype("int")
    
def online_search(stream):
        curr_r = 1
        curr_a = stream[0]
        for i in np.linspace(1,m-1,m-1):
            i = int(i)
            rd = np.random.uniform()
            if rd < 1/(i+1):
                curr_a = stream[i]
                curr_r = 1
            elif curr_a==stream[i]:
                curr_r = curr_r + 1
        
        return curr_r

class PrimeGetter:
    def __init__(self):
        self.cache = {}

    @staticmethod
    def is_prime(n):
        """
            Checks whether n is prime.
        :param n:   Value to check primality.
        :type n:    int
        :return:    False  if n is composite, otherwise
                    True   (probably prime).
        :rtype:     bool
        Notes
            May return True even though n is composite.
            Probability of such event is not greater than 1 / n**2.
        Time complexity
            O(log(n)**3)
        References
            https://en.wikipedia.org/wiki/Millerâ€“Rabin_primality_test
        """

        if n == 2 or n == 3:
            return True
        elif n == 1 or n % 2 == 0:
            return False

        d = n - 1
        r = 0
        while d % 2 == 0:  # n - 1 = d * 2**r, d - odd
            r += 1
            d >>= 1

        for i in range(r):
            a = np.random.randint(2, n)

            x = pow(a, d, n)  # x = (a**d) % n

            if x == 1 or x == n - 1:
                continue

            stop = False
            j = 0
            while j < r - 1 and not stop:
                x = pow(x, 2, n)

                if x == 1:
                    return False
                if x == n - 1:
                    stop = True

                j += 1

            if not stop:
                return False

        return True

    def get_next_prime(self, n):
        """
            Finds smallest prime greater than n.
        :param n:   Lower bound of value of prime.
        :type n:    int
        :return:    Prime p >= n.
        :rtype:     int
        Time complexity
            O(log(n)**4)
        """

        if n in self.cache:
            return self.cache[n]

        p = n + 1
        if p % 2 == 0:
            p += 1

        while not self.is_prime(p):
            p += 2

        self.cache[n] = p
        return p


# Initial point to search for a large prime
PRIMER_init = 5000000

def poly_hash(k):
    '''
    Returns a k-independent hashing function h
    :param k: int
    :param m: number of buckets
    :return: h -> h(x) = {-1, 1}
    '''
    p = np.power(2, 31) - 1
    params = np.random.randint(low=1, high=p, size=k)

    def h(x):
        res = 0
        pow_x = 1
        for i in range(k):
            res = (res + pow_x * params[i]) % p
            pow_x = (pow_x * x) % p
        return (res % 2) * 2 - 1
    return h

def poly_hash_vectorized(s1, s2, r, kwargs):
    '''
    Returns the s1*s2 hashing results generated by k-independent hashing. 
    The iteration is fine because k is typically less than 5. 

    :param k: int
    :param s1: dimension 1
    :param s2: dimension 2
    :param r: int RANGE. size of self.frequency vector = |U| = n 
    :return: a matrix of size (s1 * s2 * range) with values of {-1, 1}
    '''

    assert kwargs.get('k',None) is not None, 'kwargs does not contain k. '

    k = kwargs['k']

    prime_getter = PrimeGetter()
    p_offset = PRIMER_init

    p = np.zeros((s1, s2, 1))

    for i in range(s1):
        for j in range(s2):
            p[i, j] = prime_getter.get_next_prime(p_offset)
            p_offset += 1

    params = np.round(np.random.random(size=(s1, s2, k)) * p).astype(int)

    hashing_input = range(r)

    res = np.zeros((s1, s2, r))
    pow_x = np.ones((s1, s2, r))

    for i in range(k):
        res = (res + pow_x * params[:, :, i:i+1]) % p
        pow_x = (pow_x * hashing_input) % p
    hashed = (res % 2) * 2 - 1
    return hashed

def totally_random_vectorized(s1,s2,n, kwargs):
    return np.random.choice([1,-1], size=(s1, s2, n))

# TODO: online update

class AMS_offline(object):
    '''
    AMS Sketch for offline learning. We precompute the frequency vector of the data
    stream. Online update is not implemented yet.
    '''

    def __init__(self, stream, lambd, epsilon, hash_type, hash_kwargs, k=2, sketch_type='ams'):
        '''
        Build frequency vector
        :param stream: list of non-negative integer in range(0, RANGE)
        :param hash_generator: function that when call returns a hash function of the desired type. e.g.
        >>> hash_generator = lambda k: poly_hash(k);
        '''
        assert (k==2 and sketch_type=='ams') or (sketch_type=='Fk')

        self.stream = stream
        self.frequency_vector = get_frequency_vector(stream)

        self.F_1 = np.sum(self.frequency_vector)
        self.n = self.frequency_vector.shape[0] #size of universe. 
        self.k = k #usually 2 for second frequency moment. 
        self.lambd = lambd
        self.epsilon = epsilon
        self.sketch_type = sketch_type
        
        #compute s1 and s2 as in the paper
        self.s1,self.s2 = get_s1_s2(self.n, self.k, self.lambd, self.epsilon, self.sketch_type)
        self.truth = self.get_truth() 


        self.hash_type = hash_type
        self.hash_generator = self.get_hash_generator(hash_kwargs)
        self.hash_matrix_fnc= self.get_hash_matrix_fnc()
        self.hashing_matrix = self.hash_matrix_fnc(self.s1, self.s2, self.n, hash_kwargs); 

    def get_truth(self): 
        return np.sum(self.frequency_vector**self.k)
         

    def get_hash_generator(self, hash_kwargs):
        assert self.hash_type in ['tabulation', 'poly', 'random'] #implemented only. 

        if self.hash_type == 'tabulation':
            raise NotImplementedError()

        elif self.hash_type == 'poly':
            return lambda x: poly_hash(hash_kwargs['k'])(x)

        elif self.hash_type == 'random':
            return lambda x: np.random_choice([1,-1])


    def get_hash_matrix_fnc(self):
        assert self.hash_type in ['tabulation', 'poly', 'random'] #implemented only. 

        if self.hash_type == 'tabulation':
            raise NotImplementedError()

        elif self.hash_type == 'poly':
            return poly_hash_vectorized

        elif self.hash_type == 'random':
            return totally_random_vectorized


        
    def estimate_F2(self):
        '''
        Implement the improved estimation of F2 with matrix multiplication.
        Uniformly random hashing is used in place of the four-independent hashing
        This is not exactly the same as in the original paper, but is the most popular
        way for implementation nowadays
        :return: estimated F_2
        '''
        
        # self.hashing_matrix = np.random.choice(a = [1, -1], size=(self.s1, self.s2, self.n), replace=True)
        Z = np.matmul(self.hashing_matrix, self.frequency_vector)
        X = np.square(Z)
        Y = np.mean(X, axis=0)
        estimation = np.median(Y)

        return estimation


    def estimate_Fk(self, k):
        '''
        Implement the estimation of Fk
        :return: estimated Fk
        '''
        self.X = np.zeros((self.s1, self.s2))

        prob = self.frequency_vector / self.F_1

        for i in range(self.s1):
            for j in range(self.s2):
                idx = np.random.choice(a=n, size=1, p=prob)[0]
                r = np.random.randint(low=1, high=self.frequency_vector[idx], size=1)[0]
                self.X[i][j] = self.F_1 * (r**k - (r - 1)**k)

        Y = np.mean(self.X, axis=0)
        estimation = np.median(Y)
        
        return estimation
    
    def estimate_Fk_vectorized(self, k):
        
        prob = self.frequency_vector / self.F_1
        idx = np.random.choice(a=n, size=(self.s1, self.s2), p=prob)

        onehot_idx = np.eye(n)[idx]
        freq = np.matmul(onehot_idx, self.frequency_vector)
        offset = np.random.random(size=(self.s1, self.s2))
        r = np.round((freq - 1) * offset) + 1


        X = (np.power(r, k) - np.power(r-1, k)) * self.F_1
        Y = np.mean(X, axis=0)
        estimation = np.median(Y)
        
        return estimation
    
    def estimate_Fk_online(self, k):
        
        self.X = np.zeros((self.s1, self.s2))
        
        a = np.ones((self.s1, self.s2))*self.stream[0]
        r = np.ones((self.s1, self.s2))
        
        for i in np.linspace(1,m-1,m-1):
            i = int(i)
            
            r = r + (a == self.stream[i])
            
            rd = np.random.uniform(size=(self.s1, self.s2))
            replace = rd < 1/(i+1)
            remain = rd >= 1/(i+1)
            
            a = (a * remain) + (replace * self.stream[i])
            r = (r * remain) + (replace * 1)
            
        self.X = (np.power(r, k) - np.power(r-1, k)) * self.F_1
            

        Y = np.mean(self.X, axis=0)
        estimation = np.median(Y)
        
        return estimation